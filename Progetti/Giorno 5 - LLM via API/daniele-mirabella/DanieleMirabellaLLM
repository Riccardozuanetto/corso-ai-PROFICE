import streamlit as st
import os
from dotenv import load_dotenv
from openai import AzureOpenAI

# Carica il file .env
load_dotenv()

# Recupera le variabili dal .env
endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
subscription_key = os.getenv("AZURE_OPENAI_API_KEY")
# Usa una versione valida e già rilasciata se non impostata esplicitamente
api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT") or os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

# Inizializza il client
@st.cache_resource
def get_openai_client():
    # Evita creazione se mancano credenziali
    if not (endpoint and subscription_key):
        return None
    try:
        return AzureOpenAI(
            api_version=api_version,
            azure_endpoint=endpoint,
            api_key=subscription_key,
        )
    except Exception as e:
        st.error(f"Errore creazione client AzureOpenAI: {e}")
        return None

client = get_openai_client()

def ask_openai(user_prompt):
    if client is None:
        raise RuntimeError("Client non inizializzato (verifica variabili ambiente)")
    # Se il deployment è di tipo chat (es. gpt-4o, gpt-35-turbo) usa chat.completions
    if deployment and any(key in deployment.lower() for key in ["gpt", "turbo", "o", "mini"]):
        return client.chat.completions.create(
            model=deployment,
            messages=[{"role": "user", "content": user_prompt}],
            max_tokens=500,
            temperature=1.0
        )
    # fallback legacy completion
    return client.completions.create(
        model=deployment,
        prompt=user_prompt,
        max_tokens=500,
        temperature=1.0
    )

# Interfaccia Streamlit
st.title("Chatbot con Azure OpenAI")

# Inizializza la cronologia della chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostra la cronologia dei messaggi
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input dell'utente
prompt = st.chat_input("")

if prompt:
    # Aggiungi il messaggio dell'utente alla cronologia
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Mostra il messaggio dell'utente
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Ottieni la risposta da Azure OpenAI
    with st.chat_message("assistant"):
            try:
                response = ask_openai(prompt)
                # Determina se risposta è chat o completion
                if hasattr(response.choices[0], "message"):
                    assistant_response = response.choices[0].message.content.strip()
                else:
                    assistant_response = response.choices[0].text.strip()
                st.markdown(assistant_response)
                st.session_state.messages.append({"role": "assistant", "content": assistant_response})
            except Exception as e:
                st.error(f"Errore nella chiamata ad Azure OpenAI: {str(e)}")